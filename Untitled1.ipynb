{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61SMiQl0ZoXT",
        "outputId": "bcf1a5d3-b33a-42c7-ba89-5e21ae04b026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/LViT')\n"
      ],
      "metadata": {
        "id": "L98A2B2qad6P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhyJkf7xapiD",
        "outputId": "28090ea1-9d8d-4d49-9a90-43758ea02625"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config.py  LICENSE          \u001b[0m\u001b[01;34mMoNuSeg\u001b[0m/      README.md         train_model.py\n",
            "\u001b[01;34mdatasets\u001b[0m/  Load_Dataset.py  \u001b[01;34mnets\u001b[0m/         requirements.txt  Train_one_epoch.py\n",
            "\u001b[01;34mIMG\u001b[0m/       \u001b[01;34mLV_loss\u001b[0m/         \u001b[01;34m__pycache__\u001b[0m/  test_model.py     utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "MInxbzXeas4A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch nets/__init__.py\n",
        "!touch datasets/__init__.py\n",
        "!touch LV_loss/__init__.py\n"
      ],
      "metadata": {
        "id": "XJkxVpvpawFU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEICahrZaz2j",
        "outputId": "a09e5bf5-8e4f-47a0-a9b1-bad00b3e1f80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiOYedcla5rk",
        "outputId": "5276c3e7-e85c-4a34-8a74-54d5a95ed387"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2PHV_vcbdA1",
        "outputId": "75c6dd1c-d15f-4ccb-b430-56e4f82c4ecb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (5.29.4)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ml_collections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErToPovRbq6E",
        "outputId": "b666d238-9720-4bab-f37f-38bdab68590f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ml_collections\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from ml_collections) (1.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from ml_collections) (6.0.2)\n",
            "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml_collections\n",
            "Successfully installed ml_collections-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade requests\n",
        "!pip install --upgrade urllib3 google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "ieTOEm0ectjA",
        "outputId": "8f93499f-565a-48e6-b319-defc9899e968"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.1.31)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_storage-3.1.0-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.9/174.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, google-cloud-storage\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.19.0\n",
            "    Uninstalling google-cloud-storage-2.19.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-aiplatform 1.88.0 requires google-cloud-storage<3.0.0,>=1.32.0, but you have google-cloud-storage 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-cloud-storage-3.1.0 urllib3-2.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ab32d2957a2540b4bc7972b6d8968513"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.multiprocessing\n",
        "torch.multiprocessing.set_start_method('spawn', force=True)\n"
      ],
      "metadata": {
        "id": "r_Dhc3qBdiJn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/LViT')\n"
      ],
      "metadata": {
        "id": "Rt9KFEIMdDY4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wc9p4I-yxrW8",
        "outputId": "217c6bfb-ae26-42ae-db1c-bafe1b23976f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->thop)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->thop)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->thop)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->thop)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->thop)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->thop)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "8029f886800e49e6a03805c092e812c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from tensorboardX import SummaryWriter\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.backends import cudnn\n",
        "import logging\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from nets.LViT import LViT\n",
        "from Load_Dataset import RandomGenerator, ValGenerator, ImageToImage2D, LV2D\n",
        "import Config\n",
        "from Train_one_epoch import train_one_epoch, print_summary\n",
        "from utils import CosineAnnealingWarmRestarts, WeightedDiceBCE, WeightedDiceCE, read_text, read_text_LV, save_on_batch\n",
        "from thop import profile\n",
        "\n",
        "# Set device for GPU usage if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def logger_config(log_path):\n",
        "    loggerr = logging.getLogger()\n",
        "    loggerr.setLevel(level=logging.INFO)\n",
        "    handler = logging.FileHandler(log_path, encoding='UTF-8')\n",
        "    handler.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(message)s')\n",
        "    handler.setFormatter(formatter)\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    loggerr.addHandler(handler)\n",
        "    loggerr.addHandler(console)\n",
        "    return loggerr\n",
        "\n",
        "def save_checkpoint(state, save_path):\n",
        "    '''\n",
        "        Save the current model.\n",
        "        If the model is the best model since the beginning of the training\n",
        "        it will be copied.\n",
        "    '''\n",
        "    logger.info('\\t Saving to {}'.format(save_path))\n",
        "    if not os.path.isdir(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    epoch = state['epoch']  # epoch number\n",
        "    best_model = state['best_model']  # bool\n",
        "    model = state['model']  # model type\n",
        "\n",
        "    if best_model:\n",
        "        filename = save_path + '/' + \\\n",
        "                   'best_model-{}.pth.tar'.format(model)\n",
        "    else:\n",
        "        filename = save_path + '/' + \\\n",
        "                   'model-{}-{:02d}.pth.tar'.format(model, epoch)\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    random.seed(Config.seed + worker_id)\n",
        "\n",
        "##################################################################################\n",
        "# =================================================================================\n",
        "#          Main Loop: load model,\n",
        "# =================================================================================\n",
        "##################################################################################\n",
        "def main_loop(batch_size=Config.batch_size, model_type='', tensorboard=True):\n",
        "    # Load train and val data\n",
        "    train_tf = transforms.Compose([RandomGenerator(output_size=[Config.img_size, Config.img_size])])\n",
        "    val_tf = ValGenerator(output_size=[Config.img_size, Config.img_size])\n",
        "\n",
        "    if Config.task_name == 'MoNuSeg':\n",
        "        train_text = read_text(Config.train_dataset + 'Train_text.xlsx')\n",
        "        val_text = read_text(Config.val_dataset + 'Val_text.xlsx')\n",
        "        train_dataset = ImageToImage2D(Config.train_dataset, Config.task_name, train_text, train_tf,\n",
        "                                       image_size=Config.img_size)\n",
        "        val_dataset = ImageToImage2D(Config.val_dataset, Config.task_name, val_text, val_tf, image_size=Config.img_size)\n",
        "    elif Config.task_name == 'Covid19':\n",
        "        text = read_text(Config.task_dataset + 'Train_Val_text.xlsx')\n",
        "        train_dataset = ImageToImage2D(Config.train_dataset, Config.task_name, text, train_tf,\n",
        "                                       image_size=Config.img_size)\n",
        "        val_dataset = ImageToImage2D(Config.val_dataset, Config.task_name, text, val_tf, image_size=Config.img_size)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=Config.batch_size,\n",
        "                              shuffle=True,\n",
        "                              worker_init_fn=worker_init_fn,\n",
        "                              num_workers=0,\n",
        "                              pin_memory=True)\n",
        "\n",
        "    val_loader = DataLoader(val_dataset,\n",
        "                            batch_size=Config.batch_size,\n",
        "                            shuffle=True,\n",
        "                            worker_init_fn=worker_init_fn,\n",
        "                            num_workers=0,\n",
        "                            pin_memory=True)\n",
        "\n",
        "    lr = Config.learning_rate\n",
        "    logger.info(model_type)\n",
        "\n",
        "    if model_type == 'LViT':\n",
        "        config_vit = Config.get_CTranS_config()\n",
        "        logger.info('transformer head num: {}'.format(config_vit.transformer.num_heads))\n",
        "        logger.info('transformer layers num: {}'.format(config_vit.transformer.num_layers))\n",
        "        logger.info('transformer expand ratio: {}'.format(config_vit.expand_ratio))\n",
        "        model = LViT(config_vit, n_channels=Config.n_channels, n_classes=Config.n_labels)\n",
        "\n",
        "    elif model_type == 'LViT_pretrain':\n",
        "        config_vit = Config.get_CTranS_config()\n",
        "        logger.info('transformer head num: {}'.format(config_vit.transformer.num_heads))\n",
        "        logger.info('transformer layers num: {}'.format(config_vit.transformer.num_layers))\n",
        "        logger.info('transformer expand ratio: {}'.format(config_vit.expand_ratio))\n",
        "        model = LViT(config_vit, n_channels=Config.n_channels, n_classes=Config.n_labels)\n",
        "        pretrained_UNet_model_path = \"MoNuSeg/LViT/Test_session_05.23_10h55/models/best_model-LViT.pth.tar\"\n",
        "        pretrained_UNet = torch.load(pretrained_UNet_model_path, map_location='cuda')\n",
        "        pretrained_UNet = pretrained_UNet['state_dict']\n",
        "        model2_dict = model.state_dict()\n",
        "        state_dict = {k: v for k, v in pretrained_UNet.items() if k in model2_dict.keys()}\n",
        "        print(state_dict.keys())\n",
        "        model2_dict.update(state_dict)\n",
        "        model.load_state_dict(model2_dict)\n",
        "        logger.info('Load successful!')\n",
        "\n",
        "    else:\n",
        "        raise TypeError('Please enter a valid name for the model type')\n",
        "\n",
        "    input = torch.randn(2, 3, 224, 224)\n",
        "    text = torch.randn(2, 10, 768)\n",
        "    flops, params = profile(model, inputs=(input, text,))\n",
        "    print('flops:{}'.format(flops))\n",
        "    print('params:{}'.format(params))\n",
        "    model = model.to(device)\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Let's use {0} GPUs!\".format(torch.cuda.device_count()))\n",
        "        model = nn.DataParallel(model)\n",
        "\n",
        "    criterion = WeightedDiceBCE(dice_weight=0.5, BCE_weight=0.5)\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "\n",
        "    if Config.cosineLR:\n",
        "        lr_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-4)\n",
        "    else:\n",
        "        lr_scheduler = None\n",
        "\n",
        "    if tensorboard:\n",
        "        log_dir = Config.tensorboard_folder\n",
        "        logger.info('log dir: {}'.format(log_dir))\n",
        "        if not os.path.isdir(log_dir):\n",
        "            os.makedirs(log_dir)\n",
        "        writer = SummaryWriter(log_dir)\n",
        "    else:\n",
        "        writer = None\n",
        "\n",
        "    max_dice = 0.0\n",
        "    best_epoch = 1\n",
        "    for epoch in range(5):\n",
        "        logger.info('\\n========= Epoch [{}/{}] ========='.format(epoch + 1, Config.epochs + 1))\n",
        "        logger.info(Config.session_name)\n",
        "        model.train(True)\n",
        "        logger.info('Training with batch size : {}'.format(batch_size))\n",
        "        train_one_epoch(train_loader, model, criterion, optimizer, writer, epoch, None, model_type, logger)\n",
        "\n",
        "        logger.info('Validation')\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_loss, val_dice = train_one_epoch(val_loader, model, criterion,\n",
        "                                                 optimizer, writer, epoch, lr_scheduler, model_type, logger)\n",
        "\n",
        "        if val_dice > max_dice:\n",
        "            if epoch + 1 > 5:\n",
        "                logger.info('\\t Saving best model, mean dice increased from: {:.4f} to {:.4f}'.format(max_dice, val_dice))\n",
        "                max_dice = val_dice\n",
        "                best_epoch = epoch + 1\n",
        "                save_checkpoint({'epoch': epoch,\n",
        "                                 'best_model': True,\n",
        "                                 'model': model_type,\n",
        "                                 'state_dict': model.state_dict(),\n",
        "                                 'val_loss': val_loss,\n",
        "                                 'optimizer': optimizer.state_dict()}, Config.model_path)\n",
        "\n",
        "        else:\n",
        "            logger.info('\\t Mean dice:{:.4f} does not increase, '\n",
        "                        'the best is still: {:.4f} in epoch {}'.format(val_dice, max_dice, best_epoch))\n",
        "\n",
        "        early_stopping_count = epoch - best_epoch + 1\n",
        "        logger.info('\\t early_stopping_count: {}/{}'.format(early_stopping_count, Config.early_stopping_patience))\n",
        "\n",
        "        if early_stopping_count > Config.early_stopping_patience:\n",
        "            logger.info('\\t early_stopping!')\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set deterministic behavior for reproducibility\n",
        "    deterministic = True\n",
        "    if not deterministic:\n",
        "        cudnn.benchmark = True\n",
        "        cudnn.deterministic = False\n",
        "    else:\n",
        "        cudnn.benchmark = False\n",
        "        cudnn.deterministic = True\n",
        "\n",
        "    random.seed(Config.seed)\n",
        "    np.random.seed(Config.seed)\n",
        "    torch.manual_seed(Config.seed)\n",
        "    torch.cuda.manual_seed(Config.seed)\n",
        "    torch.cuda.manual_seed_all(Config.seed)\n",
        "\n",
        "    if not os.path.isdir(Config.save_path):\n",
        "        os.makedirs(Config.save_path)\n",
        "\n",
        "    logger = logger_config(log_path=Config.logger_path)\n",
        "    model = main_loop(model_type=Config.model_name, tensorboard=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCGlPTAobMKb",
        "outputId": "5eaeb5b0-e073-4baf-bdc1-4d5de86a3b94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "INFO:root:LViT\n",
            "LViT\n",
            "INFO:root:transformer head num: 4\n",
            "transformer head num: 4\n",
            "INFO:root:transformer layers num: 4\n",
            "transformer layers num: 4\n",
            "INFO:root:transformer expand ratio: 4\n",
            "transformer expand ratio: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register count_upsample() for <class 'torch.nn.modules.upsampling.Upsample'>.\n",
            "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:log dir: MoNuSeg/LViT/Test_session_04.23_17h54/tensorboard_logs/\n",
            "log dir: MoNuSeg/LViT/Test_session_04.23_17h54/tensorboard_logs/\n",
            "INFO:root:\n",
            "========= Epoch [1/2001] =========\n",
            "\n",
            "========= Epoch [1/2001] =========\n",
            "INFO:root:Test_session_04.23_17h54\n",
            "Test_session_04.23_17h54\n",
            "INFO:root:Training with batch size : 2\n",
            "Training with batch size : 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flops:54155993856.0\n",
            "params:29719873.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:   [Train] Epoch: [1][1/12]  Loss:0.652 (Avg 0.6518) IoU:0.083 (Avg 0.0826) Dice:0.1525 (Avg 0.1525) LR 1.00e-03   (AvgTime 6.2)   \n",
            "   [Train] Epoch: [1][1/12]  Loss:0.652 (Avg 0.6518) IoU:0.083 (Avg 0.0826) Dice:0.1525 (Avg 0.1525) LR 1.00e-03   (AvgTime 6.2)   \n",
            "INFO:root:   [Train] Epoch: [1][2/12]  Loss:0.581 (Avg 0.6164) IoU:0.216 (Avg 0.1494) Dice:0.3553 (Avg 0.2539) LR 1.00e-03   (AvgTime 4.7)   \n",
            "   [Train] Epoch: [1][2/12]  Loss:0.581 (Avg 0.6164) IoU:0.216 (Avg 0.1494) Dice:0.3553 (Avg 0.2539) LR 1.00e-03   (AvgTime 4.7)   \n",
            "INFO:root:   [Train] Epoch: [1][3/12]  Loss:0.474 (Avg 0.5688) IoU:0.471 (Avg 0.2566) Dice:0.6404 (Avg 0.3828) LR 1.00e-03   (AvgTime 4.5)   \n",
            "   [Train] Epoch: [1][3/12]  Loss:0.474 (Avg 0.5688) IoU:0.471 (Avg 0.2566) Dice:0.6404 (Avg 0.3828) LR 1.00e-03   (AvgTime 4.5)   \n",
            "INFO:root:   [Train] Epoch: [1][4/12]  Loss:0.432 (Avg 0.5347) IoU:0.447 (Avg 0.3041) Dice:0.6149 (Avg 0.4408) LR 1.00e-03   (AvgTime 4.1)   \n",
            "   [Train] Epoch: [1][4/12]  Loss:0.432 (Avg 0.5347) IoU:0.447 (Avg 0.3041) Dice:0.6149 (Avg 0.4408) LR 1.00e-03   (AvgTime 4.1)   \n",
            "INFO:root:   [Train] Epoch: [1][5/12]  Loss:0.459 (Avg 0.5196) IoU:0.433 (Avg 0.3299) Dice:0.6037 (Avg 0.4734) LR 1.00e-03   (AvgTime 4.0)   \n",
            "   [Train] Epoch: [1][5/12]  Loss:0.459 (Avg 0.5196) IoU:0.433 (Avg 0.3299) Dice:0.6037 (Avg 0.4734) LR 1.00e-03   (AvgTime 4.0)   \n",
            "INFO:root:   [Train] Epoch: [1][6/12]  Loss:0.538 (Avg 0.5227) IoU:0.298 (Avg 0.3245) Dice:0.4571 (Avg 0.4707) LR 1.00e-03   (AvgTime 4.0)   \n",
            "   [Train] Epoch: [1][6/12]  Loss:0.538 (Avg 0.5227) IoU:0.298 (Avg 0.3245) Dice:0.4571 (Avg 0.4707) LR 1.00e-03   (AvgTime 4.0)   \n",
            "INFO:root:   [Train] Epoch: [1][7/12]  Loss:0.343 (Avg 0.4971) IoU:0.579 (Avg 0.3608) Dice:0.7330 (Avg 0.5081) LR 1.00e-03   (AvgTime 4.0)   \n",
            "   [Train] Epoch: [1][7/12]  Loss:0.343 (Avg 0.4971) IoU:0.579 (Avg 0.3608) Dice:0.7330 (Avg 0.5081) LR 1.00e-03   (AvgTime 4.0)   \n",
            "INFO:root:   [Train] Epoch: [1][8/12]  Loss:0.333 (Avg 0.4766) IoU:0.583 (Avg 0.3885) Dice:0.7361 (Avg 0.5366) LR 1.00e-03   (AvgTime 3.9)   \n",
            "   [Train] Epoch: [1][8/12]  Loss:0.333 (Avg 0.4766) IoU:0.583 (Avg 0.3885) Dice:0.7361 (Avg 0.5366) LR 1.00e-03   (AvgTime 3.9)   \n",
            "INFO:root:   [Train] Epoch: [1][9/12]  Loss:0.397 (Avg 0.4677) IoU:0.498 (Avg 0.4007) Dice:0.6628 (Avg 0.5507) LR 1.00e-03   (AvgTime 4.3)   \n",
            "   [Train] Epoch: [1][9/12]  Loss:0.397 (Avg 0.4677) IoU:0.498 (Avg 0.4007) Dice:0.6628 (Avg 0.5507) LR 1.00e-03   (AvgTime 4.3)   \n",
            "INFO:root:   [Train] Epoch: [1][10/12]  Loss:0.379 (Avg 0.4588) IoU:0.525 (Avg 0.4131) Dice:0.6881 (Avg 0.5644) LR 1.00e-03   (AvgTime 4.2)   \n",
            "   [Train] Epoch: [1][10/12]  Loss:0.379 (Avg 0.4588) IoU:0.525 (Avg 0.4131) Dice:0.6881 (Avg 0.5644) LR 1.00e-03   (AvgTime 4.2)   \n",
            "INFO:root:   [Train] Epoch: [1][11/12]  Loss:0.433 (Avg 0.4565) IoU:0.390 (Avg 0.4110) Dice:0.5577 (Avg 0.5638) LR 1.00e-03   (AvgTime 4.4)   \n",
            "   [Train] Epoch: [1][11/12]  Loss:0.433 (Avg 0.4565) IoU:0.390 (Avg 0.4110) Dice:0.5577 (Avg 0.5638) LR 1.00e-03   (AvgTime 4.4)   \n",
            "INFO:root:   [Train] Epoch: [1][12/12]  Loss:0.381 (Avg 0.4502) IoU:0.471 (Avg 0.4160) Dice:0.6190 (Avg 0.5684) LR 1.00e-03   (AvgTime 4.3)   \n",
            "   [Train] Epoch: [1][12/12]  Loss:0.381 (Avg 0.4502) IoU:0.471 (Avg 0.4160) Dice:0.6190 (Avg 0.5684) LR 1.00e-03   (AvgTime 4.3)   \n",
            "INFO:root:Validation\n",
            "Validation\n",
            "INFO:root:   [Val] Epoch: [1][1/3]  Loss:0.574 (Avg 0.5742) IoU:0.425 (Avg 0.4252) Dice:0.5888 (Avg 0.5888) (AvgTime 3.7)   \n",
            "   [Val] Epoch: [1][1/3]  Loss:0.574 (Avg 0.5742) IoU:0.425 (Avg 0.4252) Dice:0.5888 (Avg 0.5888) (AvgTime 3.7)   \n",
            "INFO:root:   [Val] Epoch: [1][2/3]  Loss:0.571 (Avg 0.5724) IoU:0.381 (Avg 0.4029) Dice:0.5439 (Avg 0.5664) (AvgTime 3.5)   \n",
            "   [Val] Epoch: [1][2/3]  Loss:0.571 (Avg 0.5724) IoU:0.381 (Avg 0.4029) Dice:0.5439 (Avg 0.5664) (AvgTime 3.5)   \n",
            "INFO:root:   [Val] Epoch: [1][3/3]  Loss:0.549 (Avg 0.5645) IoU:0.331 (Avg 0.3790) Dice:0.4915 (Avg 0.5414) (AvgTime 3.6)   \n",
            "   [Val] Epoch: [1][3/3]  Loss:0.549 (Avg 0.5645) IoU:0.331 (Avg 0.3790) Dice:0.4915 (Avg 0.5414) (AvgTime 3.6)   \n",
            "INFO:root:\t early_stopping_count: 0/50\n",
            "\t early_stopping_count: 0/50\n",
            "INFO:root:\n",
            "========= Epoch [2/2001] =========\n",
            "\n",
            "========= Epoch [2/2001] =========\n",
            "INFO:root:Test_session_04.23_17h54\n",
            "Test_session_04.23_17h54\n",
            "INFO:root:Training with batch size : 2\n",
            "Training with batch size : 2\n",
            "INFO:root:   [Train] Epoch: [2][1/12]  Loss:0.422 (Avg 0.4220) IoU:0.393 (Avg 0.3927) Dice:0.5610 (Avg 0.5610) LR 9.78e-04   (AvgTime 0.4)   \n",
            "   [Train] Epoch: [2][1/12]  Loss:0.422 (Avg 0.4220) IoU:0.393 (Avg 0.3927) Dice:0.5610 (Avg 0.5610) LR 9.78e-04   (AvgTime 0.4)   \n",
            "INFO:root:   [Train] Epoch: [2][2/12]  Loss:0.275 (Avg 0.3486) IoU:0.671 (Avg 0.5320) Dice:0.8029 (Avg 0.6819) LR 9.78e-04   (AvgTime 0.4)   \n",
            "   [Train] Epoch: [2][2/12]  Loss:0.275 (Avg 0.3486) IoU:0.671 (Avg 0.5320) Dice:0.8029 (Avg 0.6819) LR 9.78e-04   (AvgTime 0.4)   \n",
            "INFO:root:   [Train] Epoch: [2][3/12]  Loss:0.324 (Avg 0.3405) IoU:0.543 (Avg 0.5356) Dice:0.7010 (Avg 0.6883) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][3/12]  Loss:0.324 (Avg 0.3405) IoU:0.543 (Avg 0.5356) Dice:0.7010 (Avg 0.6883) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][4/12]  Loss:0.329 (Avg 0.3376) IoU:0.591 (Avg 0.5494) Dice:0.7415 (Avg 0.7016) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][4/12]  Loss:0.329 (Avg 0.3376) IoU:0.591 (Avg 0.5494) Dice:0.7415 (Avg 0.7016) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][5/12]  Loss:0.441 (Avg 0.3582) IoU:0.428 (Avg 0.5251) Dice:0.5862 (Avg 0.6785) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][5/12]  Loss:0.441 (Avg 0.3582) IoU:0.428 (Avg 0.5251) Dice:0.5862 (Avg 0.6785) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][6/12]  Loss:0.372 (Avg 0.3605) IoU:0.476 (Avg 0.5169) Dice:0.6321 (Avg 0.6708) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][6/12]  Loss:0.372 (Avg 0.3605) IoU:0.476 (Avg 0.5169) Dice:0.6321 (Avg 0.6708) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][7/12]  Loss:0.369 (Avg 0.3617) IoU:0.458 (Avg 0.5085) Dice:0.6228 (Avg 0.6639) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][7/12]  Loss:0.369 (Avg 0.3617) IoU:0.458 (Avg 0.5085) Dice:0.6228 (Avg 0.6639) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][8/12]  Loss:0.446 (Avg 0.3722) IoU:0.431 (Avg 0.4988) Dice:0.6016 (Avg 0.6561) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][8/12]  Loss:0.446 (Avg 0.3722) IoU:0.431 (Avg 0.4988) Dice:0.6016 (Avg 0.6561) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][9/12]  Loss:0.293 (Avg 0.3634) IoU:0.628 (Avg 0.5131) Dice:0.7715 (Avg 0.6690) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][9/12]  Loss:0.293 (Avg 0.3634) IoU:0.628 (Avg 0.5131) Dice:0.7715 (Avg 0.6690) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][10/12]  Loss:0.383 (Avg 0.3654) IoU:0.402 (Avg 0.5020) Dice:0.5635 (Avg 0.6584) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][10/12]  Loss:0.383 (Avg 0.3654) IoU:0.402 (Avg 0.5020) Dice:0.5635 (Avg 0.6584) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][11/12]  Loss:0.434 (Avg 0.3716) IoU:0.452 (Avg 0.4975) Dice:0.6207 (Avg 0.6550) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][11/12]  Loss:0.434 (Avg 0.3716) IoU:0.452 (Avg 0.4975) Dice:0.6207 (Avg 0.6550) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [2][12/12]  Loss:0.409 (Avg 0.3747) IoU:0.460 (Avg 0.4943) Dice:0.6289 (Avg 0.6528) LR 9.78e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [2][12/12]  Loss:0.409 (Avg 0.3747) IoU:0.460 (Avg 0.4943) Dice:0.6289 (Avg 0.6528) LR 9.78e-04   (AvgTime 0.3)   \n",
            "INFO:root:Validation\n",
            "Validation\n",
            "INFO:root:   [Val] Epoch: [2][1/3]  Loss:0.479 (Avg 0.4788) IoU:0.324 (Avg 0.3244) Dice:0.4888 (Avg 0.4888) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [2][1/3]  Loss:0.479 (Avg 0.4788) IoU:0.324 (Avg 0.3244) Dice:0.4888 (Avg 0.4888) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [2][2/3]  Loss:0.421 (Avg 0.4500) IoU:0.522 (Avg 0.4232) Dice:0.6851 (Avg 0.5869) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [2][2/3]  Loss:0.421 (Avg 0.4500) IoU:0.522 (Avg 0.4232) Dice:0.6851 (Avg 0.5869) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [2][3/3]  Loss:1.449 (Avg 0.7829) IoU:0.145 (Avg 0.3304) Dice:0.2248 (Avg 0.4662) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [2][3/3]  Loss:1.449 (Avg 0.7829) IoU:0.145 (Avg 0.3304) Dice:0.2248 (Avg 0.4662) (AvgTime 0.2)   \n",
            "INFO:root:\t early_stopping_count: 1/50\n",
            "\t early_stopping_count: 1/50\n",
            "INFO:root:\n",
            "========= Epoch [3/2001] =========\n",
            "\n",
            "========= Epoch [3/2001] =========\n",
            "INFO:root:Test_session_04.23_17h54\n",
            "Test_session_04.23_17h54\n",
            "INFO:root:Training with batch size : 2\n",
            "Training with batch size : 2\n",
            "INFO:root:   [Train] Epoch: [3][1/12]  Loss:0.289 (Avg 0.2888) IoU:0.643 (Avg 0.6430) Dice:0.7827 (Avg 0.7827) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][1/12]  Loss:0.289 (Avg 0.2888) IoU:0.643 (Avg 0.6430) Dice:0.7827 (Avg 0.7827) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][2/12]  Loss:0.316 (Avg 0.3023) IoU:0.571 (Avg 0.6072) Dice:0.7271 (Avg 0.7549) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][2/12]  Loss:0.316 (Avg 0.3023) IoU:0.571 (Avg 0.6072) Dice:0.7271 (Avg 0.7549) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][3/12]  Loss:0.286 (Avg 0.2967) IoU:0.620 (Avg 0.6116) Dice:0.7643 (Avg 0.7580) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][3/12]  Loss:0.286 (Avg 0.2967) IoU:0.620 (Avg 0.6116) Dice:0.7643 (Avg 0.7580) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][4/12]  Loss:0.282 (Avg 0.2931) IoU:0.618 (Avg 0.6132) Dice:0.7620 (Avg 0.7590) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][4/12]  Loss:0.282 (Avg 0.2931) IoU:0.618 (Avg 0.6132) Dice:0.7620 (Avg 0.7590) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][5/12]  Loss:0.283 (Avg 0.2912) IoU:0.621 (Avg 0.6147) Dice:0.7658 (Avg 0.7604) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][5/12]  Loss:0.283 (Avg 0.2912) IoU:0.621 (Avg 0.6147) Dice:0.7658 (Avg 0.7604) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][6/12]  Loss:0.232 (Avg 0.2814) IoU:0.689 (Avg 0.6271) Dice:0.8144 (Avg 0.7694) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][6/12]  Loss:0.232 (Avg 0.2814) IoU:0.689 (Avg 0.6271) Dice:0.8144 (Avg 0.7694) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][7/12]  Loss:0.291 (Avg 0.2827) IoU:0.620 (Avg 0.6260) Dice:0.7652 (Avg 0.7688) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][7/12]  Loss:0.291 (Avg 0.2827) IoU:0.620 (Avg 0.6260) Dice:0.7652 (Avg 0.7688) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][8/12]  Loss:0.345 (Avg 0.2905) IoU:0.553 (Avg 0.6169) Dice:0.7060 (Avg 0.7609) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][8/12]  Loss:0.345 (Avg 0.2905) IoU:0.553 (Avg 0.6169) Dice:0.7060 (Avg 0.7609) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][9/12]  Loss:0.378 (Avg 0.3002) IoU:0.431 (Avg 0.5962) Dice:0.6019 (Avg 0.7433) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][9/12]  Loss:0.378 (Avg 0.3002) IoU:0.431 (Avg 0.5962) Dice:0.6019 (Avg 0.7433) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][10/12]  Loss:0.346 (Avg 0.3048) IoU:0.560 (Avg 0.5926) Dice:0.7161 (Avg 0.7405) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][10/12]  Loss:0.346 (Avg 0.3048) IoU:0.560 (Avg 0.5926) Dice:0.7161 (Avg 0.7405) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][11/12]  Loss:0.350 (Avg 0.3089) IoU:0.545 (Avg 0.5883) Dice:0.7051 (Avg 0.7373) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][11/12]  Loss:0.350 (Avg 0.3089) IoU:0.545 (Avg 0.5883) Dice:0.7051 (Avg 0.7373) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [3][12/12]  Loss:0.334 (Avg 0.3111) IoU:0.514 (Avg 0.5821) Dice:0.6748 (Avg 0.7321) LR 9.14e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [3][12/12]  Loss:0.334 (Avg 0.3111) IoU:0.514 (Avg 0.5821) Dice:0.6748 (Avg 0.7321) LR 9.14e-04   (AvgTime 0.3)   \n",
            "INFO:root:Validation\n",
            "Validation\n",
            "INFO:root:   [Val] Epoch: [3][1/3]  Loss:0.431 (Avg 0.4307) IoU:0.393 (Avg 0.3928) Dice:0.5333 (Avg 0.5333) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [3][1/3]  Loss:0.431 (Avg 0.4307) IoU:0.393 (Avg 0.3928) Dice:0.5333 (Avg 0.5333) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [3][2/3]  Loss:0.485 (Avg 0.4581) IoU:0.356 (Avg 0.3746) Dice:0.5086 (Avg 0.5209) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [3][2/3]  Loss:0.485 (Avg 0.4581) IoU:0.356 (Avg 0.3746) Dice:0.5086 (Avg 0.5209) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [3][3/3]  Loss:3.126 (Avg 1.3475) IoU:0.029 (Avg 0.2593) Dice:0.0542 (Avg 0.3653) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [3][3/3]  Loss:3.126 (Avg 1.3475) IoU:0.029 (Avg 0.2593) Dice:0.0542 (Avg 0.3653) (AvgTime 0.2)   \n",
            "INFO:root:\t early_stopping_count: 2/50\n",
            "\t early_stopping_count: 2/50\n",
            "INFO:root:\n",
            "========= Epoch [4/2001] =========\n",
            "\n",
            "========= Epoch [4/2001] =========\n",
            "INFO:root:Test_session_04.23_17h54\n",
            "Test_session_04.23_17h54\n",
            "INFO:root:Training with batch size : 2\n",
            "Training with batch size : 2\n",
            "INFO:root:   [Train] Epoch: [4][1/12]  Loss:0.266 (Avg 0.2663) IoU:0.634 (Avg 0.6340) Dice:0.7753 (Avg 0.7753) LR 8.15e-04   (AvgTime 0.2)   \n",
            "   [Train] Epoch: [4][1/12]  Loss:0.266 (Avg 0.2663) IoU:0.634 (Avg 0.6340) Dice:0.7753 (Avg 0.7753) LR 8.15e-04   (AvgTime 0.2)   \n",
            "INFO:root:   [Train] Epoch: [4][2/12]  Loss:0.304 (Avg 0.2849) IoU:0.621 (Avg 0.6273) Dice:0.7641 (Avg 0.7697) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][2/12]  Loss:0.304 (Avg 0.2849) IoU:0.621 (Avg 0.6273) Dice:0.7641 (Avg 0.7697) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][3/12]  Loss:0.245 (Avg 0.2718) IoU:0.697 (Avg 0.6504) Dice:0.8201 (Avg 0.7865) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][3/12]  Loss:0.245 (Avg 0.2718) IoU:0.697 (Avg 0.6504) Dice:0.8201 (Avg 0.7865) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][4/12]  Loss:0.318 (Avg 0.2832) IoU:0.493 (Avg 0.6110) Dice:0.6592 (Avg 0.7547) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][4/12]  Loss:0.318 (Avg 0.2832) IoU:0.493 (Avg 0.6110) Dice:0.6592 (Avg 0.7547) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][5/12]  Loss:0.317 (Avg 0.2900) IoU:0.547 (Avg 0.5983) Dice:0.7045 (Avg 0.7446) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][5/12]  Loss:0.317 (Avg 0.2900) IoU:0.547 (Avg 0.5983) Dice:0.7045 (Avg 0.7446) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][6/12]  Loss:0.304 (Avg 0.2924) IoU:0.555 (Avg 0.5911) Dice:0.7129 (Avg 0.7393) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][6/12]  Loss:0.304 (Avg 0.2924) IoU:0.555 (Avg 0.5911) Dice:0.7129 (Avg 0.7393) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][7/12]  Loss:0.223 (Avg 0.2824) IoU:0.692 (Avg 0.6056) Dice:0.8168 (Avg 0.7504) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][7/12]  Loss:0.223 (Avg 0.2824) IoU:0.692 (Avg 0.6056) Dice:0.8168 (Avg 0.7504) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][8/12]  Loss:0.359 (Avg 0.2921) IoU:0.539 (Avg 0.5972) Dice:0.6982 (Avg 0.7439) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][8/12]  Loss:0.359 (Avg 0.2921) IoU:0.539 (Avg 0.5972) Dice:0.6982 (Avg 0.7439) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][9/12]  Loss:0.266 (Avg 0.2892) IoU:0.609 (Avg 0.5986) Dice:0.7572 (Avg 0.7454) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][9/12]  Loss:0.266 (Avg 0.2892) IoU:0.609 (Avg 0.5986) Dice:0.7572 (Avg 0.7454) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][10/12]  Loss:0.326 (Avg 0.2928) IoU:0.539 (Avg 0.5926) Dice:0.6949 (Avg 0.7403) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][10/12]  Loss:0.326 (Avg 0.2928) IoU:0.539 (Avg 0.5926) Dice:0.6949 (Avg 0.7403) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][11/12]  Loss:0.315 (Avg 0.2948) IoU:0.561 (Avg 0.5897) Dice:0.7186 (Avg 0.7383) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][11/12]  Loss:0.315 (Avg 0.2948) IoU:0.561 (Avg 0.5897) Dice:0.7186 (Avg 0.7383) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [4][12/12]  Loss:0.288 (Avg 0.2943) IoU:0.580 (Avg 0.5889) Dice:0.7317 (Avg 0.7378) LR 8.15e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [4][12/12]  Loss:0.288 (Avg 0.2943) IoU:0.580 (Avg 0.5889) Dice:0.7317 (Avg 0.7378) LR 8.15e-04   (AvgTime 0.3)   \n",
            "INFO:root:Validation\n",
            "Validation\n",
            "INFO:root:   [Val] Epoch: [4][1/3]  Loss:0.302 (Avg 0.3019) IoU:0.598 (Avg 0.5985) Dice:0.7472 (Avg 0.7472) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [4][1/3]  Loss:0.302 (Avg 0.3019) IoU:0.598 (Avg 0.5985) Dice:0.7472 (Avg 0.7472) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [4][2/3]  Loss:1.184 (Avg 0.7429) IoU:0.228 (Avg 0.4134) Dice:0.3135 (Avg 0.5304) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [4][2/3]  Loss:1.184 (Avg 0.7429) IoU:0.228 (Avg 0.4134) Dice:0.3135 (Avg 0.5304) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [4][3/3]  Loss:0.409 (Avg 0.6316) IoU:0.454 (Avg 0.4268) Dice:0.5984 (Avg 0.5531) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [4][3/3]  Loss:0.409 (Avg 0.6316) IoU:0.454 (Avg 0.4268) Dice:0.5984 (Avg 0.5531) (AvgTime 0.2)   \n",
            "INFO:root:\t early_stopping_count: 3/50\n",
            "\t early_stopping_count: 3/50\n",
            "INFO:root:\n",
            "========= Epoch [5/2001] =========\n",
            "\n",
            "========= Epoch [5/2001] =========\n",
            "INFO:root:Test_session_04.23_17h54\n",
            "Test_session_04.23_17h54\n",
            "INFO:root:Training with batch size : 2\n",
            "Training with batch size : 2\n",
            "INFO:root:   [Train] Epoch: [5][1/12]  Loss:0.347 (Avg 0.3469) IoU:0.548 (Avg 0.5484) Dice:0.7069 (Avg 0.7069) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][1/12]  Loss:0.347 (Avg 0.3469) IoU:0.548 (Avg 0.5484) Dice:0.7069 (Avg 0.7069) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][2/12]  Loss:0.245 (Avg 0.2958) IoU:0.691 (Avg 0.6198) Dice:0.8158 (Avg 0.7614) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][2/12]  Loss:0.245 (Avg 0.2958) IoU:0.691 (Avg 0.6198) Dice:0.8158 (Avg 0.7614) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][3/12]  Loss:0.298 (Avg 0.2966) IoU:0.501 (Avg 0.5802) Dice:0.6626 (Avg 0.7285) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][3/12]  Loss:0.298 (Avg 0.2966) IoU:0.501 (Avg 0.5802) Dice:0.6626 (Avg 0.7285) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][4/12]  Loss:0.252 (Avg 0.2854) IoU:0.631 (Avg 0.5929) Dice:0.7723 (Avg 0.7394) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][4/12]  Loss:0.252 (Avg 0.2854) IoU:0.631 (Avg 0.5929) Dice:0.7723 (Avg 0.7394) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][5/12]  Loss:0.363 (Avg 0.3010) IoU:0.511 (Avg 0.5766) Dice:0.6757 (Avg 0.7267) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][5/12]  Loss:0.363 (Avg 0.3010) IoU:0.511 (Avg 0.5766) Dice:0.6757 (Avg 0.7267) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][6/12]  Loss:0.264 (Avg 0.2948) IoU:0.627 (Avg 0.5850) Dice:0.7711 (Avg 0.7341) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][6/12]  Loss:0.264 (Avg 0.2948) IoU:0.627 (Avg 0.5850) Dice:0.7711 (Avg 0.7341) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][7/12]  Loss:0.244 (Avg 0.2875) IoU:0.696 (Avg 0.6009) Dice:0.8202 (Avg 0.7464) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][7/12]  Loss:0.244 (Avg 0.2875) IoU:0.696 (Avg 0.6009) Dice:0.8202 (Avg 0.7464) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][8/12]  Loss:0.348 (Avg 0.2951) IoU:0.540 (Avg 0.5932) Dice:0.7010 (Avg 0.7407) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][8/12]  Loss:0.348 (Avg 0.2951) IoU:0.540 (Avg 0.5932) Dice:0.7010 (Avg 0.7407) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][9/12]  Loss:0.266 (Avg 0.2918) IoU:0.623 (Avg 0.5966) Dice:0.7673 (Avg 0.7437) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][9/12]  Loss:0.266 (Avg 0.2918) IoU:0.623 (Avg 0.5966) Dice:0.7673 (Avg 0.7437) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][10/12]  Loss:0.267 (Avg 0.2893) IoU:0.644 (Avg 0.6013) Dice:0.7826 (Avg 0.7475) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][10/12]  Loss:0.267 (Avg 0.2893) IoU:0.644 (Avg 0.6013) Dice:0.7826 (Avg 0.7475) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][11/12]  Loss:0.225 (Avg 0.2834) IoU:0.671 (Avg 0.6076) Dice:0.8030 (Avg 0.7526) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][11/12]  Loss:0.225 (Avg 0.2834) IoU:0.671 (Avg 0.6076) Dice:0.8030 (Avg 0.7526) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:   [Train] Epoch: [5][12/12]  Loss:0.399 (Avg 0.2931) IoU:0.445 (Avg 0.5940) Dice:0.6151 (Avg 0.7411) LR 6.89e-04   (AvgTime 0.3)   \n",
            "   [Train] Epoch: [5][12/12]  Loss:0.399 (Avg 0.2931) IoU:0.445 (Avg 0.5940) Dice:0.6151 (Avg 0.7411) LR 6.89e-04   (AvgTime 0.3)   \n",
            "INFO:root:Validation\n",
            "Validation\n",
            "INFO:root:   [Val] Epoch: [5][1/3]  Loss:0.320 (Avg 0.3204) IoU:0.580 (Avg 0.5799) Dice:0.7339 (Avg 0.7339) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [5][1/3]  Loss:0.320 (Avg 0.3204) IoU:0.580 (Avg 0.5799) Dice:0.7339 (Avg 0.7339) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [5][2/3]  Loss:0.645 (Avg 0.4829) IoU:0.291 (Avg 0.4356) Dice:0.3721 (Avg 0.5530) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [5][2/3]  Loss:0.645 (Avg 0.4829) IoU:0.291 (Avg 0.4356) Dice:0.3721 (Avg 0.5530) (AvgTime 0.2)   \n",
            "INFO:root:   [Val] Epoch: [5][3/3]  Loss:0.295 (Avg 0.4204) IoU:0.600 (Avg 0.4903) Dice:0.7493 (Avg 0.6185) (AvgTime 0.2)   \n",
            "   [Val] Epoch: [5][3/3]  Loss:0.295 (Avg 0.4204) IoU:0.600 (Avg 0.4903) Dice:0.7493 (Avg 0.6185) (AvgTime 0.2)   \n",
            "INFO:root:\t early_stopping_count: 4/50\n",
            "\t early_stopping_count: 4/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim\n",
        "from Load_Dataset import ValGenerator, ImageToImage2D\n",
        "from torch.utils.data import DataLoader\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import Config as config\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from nets.LViT import LViT\n",
        "from utils import *\n",
        "import cv2\n",
        "\n",
        "\n",
        "def show_image_with_dice(predict_save, labs, save_path):\n",
        "    tmp_lbl = (labs).astype(np.float32)\n",
        "    tmp_3dunet = (predict_save).astype(np.float32)\n",
        "    dice_pred = 2 * np.sum(tmp_lbl * tmp_3dunet) / (np.sum(tmp_lbl) + np.sum(tmp_3dunet) + 1e-5)\n",
        "    # dice_show = \"%.3f\" % (dice_pred)\n",
        "    iou_pred = jaccard_score(tmp_lbl.reshape(-1), tmp_3dunet.reshape(-1))\n",
        "    # fig, ax = plt.subplots()\n",
        "    # plt.gca().add_patch(patches.Rectangle(xy=(4, 4),width=120,height=20,color=\"white\",linewidth=1))\n",
        "    if config.task_name == \"MoNuSeg\":\n",
        "        predict_save = cv2.pyrUp(predict_save, (448, 448))\n",
        "        predict_save = cv2.resize(predict_save, (2000, 2000))\n",
        "        # kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32) #定义一个核\n",
        "        # predict_save = cv2.filter2D(predict_save, -1, kernel=kernel)\n",
        "        cv2.imwrite(save_path, predict_save * 255)\n",
        "    else:\n",
        "        cv2.imwrite(save_path, predict_save * 255)\n",
        "    # plt.imshow(predict_save * 255,cmap='gray')\n",
        "    # plt.text(x=10, y=24, s=\"Dice:\" + str(dice_show), fontsize=5)\n",
        "    # plt.axis(\"off\")\n",
        "    # remove the white borders\n",
        "    # height, width = predict_save.shape\n",
        "    # fig.set_size_inches(width / 100.0 / 3.0, height / 100.0 / 3.0)\n",
        "    # plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
        "    # plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
        "    # plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0, wspace=0)\n",
        "    # plt.margins(0, 0)\n",
        "    # plt.savefig(save_path, dpi=2000)\n",
        "    # plt.close()\n",
        "    return dice_pred, iou_pred\n",
        "\n",
        "\n",
        "def vis_and_save_heatmap(model, input_img, text, img_RGB, labs, vis_save_path, dice_pred, dice_ens):\n",
        "    model.eval()\n",
        "\n",
        "    output = model(input_img.cuda(), text.cuda())\n",
        "    pred_class = torch.where(output > 0.5, torch.ones_like(output), torch.zeros_like(output))\n",
        "    predict_save = pred_class[0].cpu().data.numpy()\n",
        "    predict_save = np.reshape(predict_save, (config.img_size, config.img_size))\n",
        "    dice_pred_tmp, iou_tmp = show_image_with_dice(predict_save, labs,\n",
        "                                                  save_path=vis_save_path + '_predict' + model_type + '.jpg')\n",
        "    return dice_pred_tmp, iou_tmp\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    test_session ='test-30epoch'\n",
        "\n",
        "    if config.task_name == \"MoNuSeg\":\n",
        "        test_num = 14\n",
        "        model_type = config.model_name\n",
        "        model_path = \"/content/drive/MyDrive/LViT/MoNuSeg/LViT/Test_session_04.23_16h21/models/best_model-LViT.pth.tar\"\n",
        "\n",
        "    elif config.task_name == \"Covid19\":\n",
        "        test_num = 2113\n",
        "        model_type = config.model_name\n",
        "        model_path = \"./Covid19/\" + model_type + \"/\" + test_session + \"/models/best_model-\" + model_type + \".pth.tar\"\n",
        "\n",
        "    save_path = config.task_name + '/' + model_type + '/' + test_session + '/'\n",
        "    vis_path = \"./\" + config.task_name + '_visualize_test/'\n",
        "    if not os.path.exists(vis_path):\n",
        "        os.makedirs(vis_path)\n",
        "\n",
        "    checkpoint = torch.load(model_path, map_location='cuda')\n",
        "\n",
        "    if model_type == 'LViT':\n",
        "        config_vit = config.get_CTranS_config()\n",
        "        model = LViT(config_vit, n_channels=config.n_channels, n_classes=config.n_labels)\n",
        "\n",
        "    elif model_type == 'LViT_pretrain':\n",
        "        config_vit = config.get_CTranS_config()\n",
        "        model = LViT(config_vit, n_channels=config.n_channels, n_classes=config.n_labels)\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise TypeError('Please enter a valid name for the model type')\n",
        "\n",
        "    model = model.cuda()\n",
        "    if torch.cuda.device_count() > 1:\n",
        "       print(\"Let's use {0} GPUs!\".format(torch.cuda.device_count()))\n",
        "       model = nn.DataParallel(model)\n",
        "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
        "    print('Model loaded !')\n",
        "    tf_test = ValGenerator(output_size=[config.img_size, config.img_size])\n",
        "    test_text = read_text(config.test_dataset + 'Test_text.xlsx')\n",
        "    test_dataset = ImageToImage2D(config.test_dataset, config.task_name, test_text, tf_test, image_size=config.img_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    dice_pred = 0.0\n",
        "    iou_pred = 0.0\n",
        "    dice_ens = 0.0\n",
        "\n",
        "    with tqdm(total=test_num, desc='Test visualize', unit='img', ncols=70, leave=True) as pbar:\n",
        "        for i, (sampled_batch, names) in enumerate(test_loader, 1):\n",
        "            # print(names)\n",
        "            test_data, test_label, test_text = sampled_batch['image'], sampled_batch['label'], sampled_batch['text']\n",
        "            arr = test_data.numpy()\n",
        "            arr = arr.astype(np.float32())\n",
        "            lab = test_label.data.numpy()\n",
        "            img_lab = np.reshape(lab, (lab.shape[1], lab.shape[2])) * 255\n",
        "            fig, ax = plt.subplots()\n",
        "            plt.imshow(img_lab, cmap='gray')\n",
        "            plt.axis(\"off\")\n",
        "            height, width = config.img_size, config.img_size\n",
        "            fig.set_size_inches(width / 100.0 / 3.0, height / 100.0 / 3.0)\n",
        "            plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
        "            plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
        "            plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0, wspace=0)\n",
        "            plt.margins(0, 0)\n",
        "            plt.savefig(vis_path + str(names) + \"_lab.jpg\", dpi=300)\n",
        "            plt.close()\n",
        "            input_img = torch.from_numpy(arr)\n",
        "            dice_pred_t, iou_pred_t = vis_and_save_heatmap(model, input_img, test_text, None, lab,\n",
        "                                                           vis_path + str(names),\n",
        "                                                           dice_pred=dice_pred, dice_ens=dice_ens)\n",
        "            dice_pred += dice_pred_t\n",
        "            iou_pred += iou_pred_t\n",
        "            torch.cuda.empty_cache()\n",
        "            pbar.update()\n",
        "    print(\"dice_pred\", dice_pred / test_num)\n",
        "    print(\"iou_pred\", iou_pred / test_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBxHzePhbldb",
        "outputId": "446304a9-d7f4-4b88-ed0f-45bad048eacd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test visualize: 100%|████████████████| 14/14 [00:31<00:00,  2.28s/img]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dice_pred 0.77792543\n",
            "iou_pred 0.64980370040251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dice = dice_pred / test_num\n",
        "final_iou = iou_pred / test_num\n",
        "\n",
        "print(f\"\\n===== Evaluation Results on {config.task_name} ({test_num} samples) =====\")\n",
        "print(f\"Average Dice Score : {final_dice:.4f}\")\n",
        "print(f\"Average IoU Score  : {final_iou:.4f}\")\n",
        "print(\"=====================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mSwyjqq0kQH",
        "outputId": "fb2d7b5f-4c81-4a4a-f75b-2e41ed73418d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Evaluation Results on MoNuSeg (14 samples) =====\n",
            "Average Dice Score : 0.7779\n",
            "Average IoU Score  : 0.6498\n",
            "=====================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dice = dice_pred / test_num\n",
        "final_iou = iou_pred / test_num\n",
        "\n",
        "print(f\"\\n===== Evaluation Results on {config.task_name} ({test_num} samples) =====\")\n",
        "print(f\"Average Dice Score : {final_dice:.4f}\")\n",
        "print(f\"Average IoU Score  : {final_iou:.4f}\")\n",
        "print(\"=====================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnfUeBjG1H-W",
        "outputId": "b5e814f0-c1d0-4b40-a125-e024eb4b6001"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Evaluation Results on MoNuSeg (14 samples) =====\n",
            "Average Dice Score : 0.7779\n",
            "Average IoU Score  : 0.6498\n",
            "=====================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dice_scores = []\n",
        "iou_scores = []\n",
        "\n",
        "# inside the loop\n",
        "dice_scores.append(dice_pred_t)\n",
        "iou_scores.append(iou_pred_t)\n"
      ],
      "metadata": {
        "id": "fBGgbD8F1V_v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(dice_scores, bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Dice Score Distribution')\n",
        "plt.xlabel('Dice Score')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(iou_scores, bins=20, color='salmon', edgecolor='black')\n",
        "plt.title('IoU Score Distribution')\n",
        "plt.xlabel('IoU Score')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(vis_path, \"score_distribution.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "HZKy4Lcv1NJU",
        "outputId": "f2017be8-d093-4cdd-850f-2f37dd148c00"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}